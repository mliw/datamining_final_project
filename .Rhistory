test_X = subset(test_batch,select = -log1p_SalePrice)
test_Y = test_batch$log1p_SalePrice
test_X = as.matrix(test_X)
test_Y = as.matrix(test_Y)
svm_prediction = predict(svm_model,test_X)
batch_err = rmse(test_Y,svm_prediction)
err_vec = c(err_vec,batch_err)
}
}
}
}
}
library(caret)
library(glmnet)
library(e1071)
library(xgboost)
library(ModelMetrics)
# 0 Functions
# divide data into 5 folds
divide_data = function(data,rand_num){
set.seed(rand_num)
indexs = createFolds(1:dim(data)[1], k = 5, list = TRUE, returnTrain = FALSE)
return(indexs)
# test_data = data[indexs[[i]],]
# train_data = data[-indexs[[i]],]
}
# 1 Load data
train_data = read.csv("data/train_data_R.csv", stringsAsFactors=TRUE)
test_data = read.csv("data/test_data_R.csv", stringsAsFactors=TRUE)
train_data = subset(train_data,select = -X)
train_data = subset(train_data,select = -Id)
test_id = test_data$Id
test_data = subset(test_data,select = -X)
test_data = subset(test_data,select = -Id)
test_data = subset(test_data,select = -log1p_SalePrice)
# 2 Fit on the whole data set to get best_features(top25)
nround = 100
param = list(max_depth=2,eta=0.3, silent=0)
X = subset(train_data,select = -log1p_SalePrice)
Y = train_data$log1p_SalePrice
X = as.matrix(X)
Y = as.matrix(Y)
dtrain = xgb.DMatrix(X,label=Y)
bst = xgb.train(params = param, data = dtrain, nrounds = nround, nthread = 2)
importance_matrix = xgb.importance(model = bst)
best_features = importance_matrix$Feature[1:25]
train_data = train_data[,c(best_features,"log1p_SalePrice")]
# 3 Tunning parameters for SVM
library(caret)
for (eps_value in seq(0,1,0.2)){
for (shrinking in c(TRUE,FALSE)){
for (kernel_value in c("linear","polynomial","radial","sigmoid")){
X = subset(train_data,select=-log1p_SalePrice)
for (rd_state in 1:20){
indexs = divide_data(train_data,rd_state)
err_vec = c()
for (i in 1:5){
train_batch = train_data[-indexs[[i]],c(best_features,"log1p_SalePrice")]
test_batch = train_data[indexs[[i]],c(best_features,"log1p_SalePrice")]
X = subset(train_batch,select = -log1p_SalePrice)
Y = train_batch$log1p_SalePrice
X = as.matrix(X)
Y = as.matrix(Y)
svm_model = svm(X,Y,eps=eps_value,kernel=kernel_value)
test_X = subset(test_batch,select = -log1p_SalePrice)
test_Y = test_batch$log1p_SalePrice
test_X = as.matrix(test_X)
test_Y = as.matrix(test_Y)
svm_prediction = predict(svm_model,test_X)
batch_err = rmse(test_Y,svm_prediction)
err_vec = c(err_vec,batch_err)
}
}
}
}
}
err_vec
final_result = data.frame()
library(caret)
library(glmnet)
library(e1071)
library(xgboost)
library(ModelMetrics)
# 0 Functions
# divide data into 5 folds
divide_data = function(data,rand_num){
set.seed(rand_num)
indexs = createFolds(1:dim(data)[1], k = 5, list = TRUE, returnTrain = FALSE)
return(indexs)
# test_data = data[indexs[[i]],]
# train_data = data[-indexs[[i]],]
}
# 1 Load data
train_data = read.csv("data/train_data_R.csv", stringsAsFactors=TRUE)
test_data = read.csv("data/test_data_R.csv", stringsAsFactors=TRUE)
train_data = subset(train_data,select = -X)
train_data = subset(train_data,select = -Id)
test_id = test_data$Id
test_data = subset(test_data,select = -X)
test_data = subset(test_data,select = -Id)
test_data = subset(test_data,select = -log1p_SalePrice)
# 2 Fit on the whole data set to get best_features(top25)
nround = 100
param = list(max_depth=2,eta=0.3, silent=0)
X = subset(train_data,select = -log1p_SalePrice)
Y = train_data$log1p_SalePrice
X = as.matrix(X)
Y = as.matrix(Y)
dtrain = xgb.DMatrix(X,label=Y)
bst = xgb.train(params = param, data = dtrain, nrounds = nround, nthread = 2)
importance_matrix = xgb.importance(model = bst)
best_features = importance_matrix$Feature[1:25]
train_data = train_data[,c(best_features,"log1p_SalePrice")]
# 3 Tunning parameters for SVM
final_result = data.frame()
for (eps_value in seq(0,1,0.2)){
for (kernel_value in c("linear","polynomial","radial","sigmoid")){
X = subset(train_data,select=-log1p_SalePrice)
err_vec_high = c()
for (rd_state in 1:20){
indexs = divide_data(train_data,rd_state)
err_vec = c()
for (i in 1:5){
train_batch = train_data[-indexs[[i]],c(best_features,"log1p_SalePrice")]
test_batch = train_data[indexs[[i]],c(best_features,"log1p_SalePrice")]
X = subset(train_batch,select = -log1p_SalePrice)
Y = train_batch$log1p_SalePrice
X = as.matrix(X)
Y = as.matrix(Y)
svm_model = svm(X,Y,eps=eps_value,kernel=kernel_value)
test_X = subset(test_batch,select = -log1p_SalePrice)
test_Y = test_batch$log1p_SalePrice
test_X = as.matrix(test_X)
test_Y = as.matrix(test_Y)
svm_prediction = predict(svm_model,test_X)
batch_err = rmse(test_Y,svm_prediction)
err_vec = c(err_vec,batch_err)
}
mean_cv_err = mean(err_vec)
err_vec_high = c(err_vec_high,mean_cv_err)
}
tem_result = c(eps_value,kernel_value,mean(err_vec_high))
print(tem_result)
}
}
library(caret)
library(glmnet)
library(e1071)
library(xgboost)
library(ModelMetrics)
# 0 Functions
# divide data into 5 folds
divide_data = function(data,rand_num){
set.seed(rand_num)
indexs = createFolds(1:dim(data)[1], k = 5, list = TRUE, returnTrain = FALSE)
return(indexs)
# test_data = data[indexs[[i]],]
# train_data = data[-indexs[[i]],]
}
# 1 Load data
train_data = read.csv("data/train_data_R.csv", stringsAsFactors=TRUE)
test_data = read.csv("data/test_data_R.csv", stringsAsFactors=TRUE)
train_data = subset(train_data,select = -X)
train_data = subset(train_data,select = -Id)
test_id = test_data$Id
test_data = subset(test_data,select = -X)
test_data = subset(test_data,select = -Id)
test_data = subset(test_data,select = -log1p_SalePrice)
# 2 Fit on the whole data set to get best_features(top25)
nround = 100
param = list(max_depth=2,eta=0.3, silent=0)
X = subset(train_data,select = -log1p_SalePrice)
Y = train_data$log1p_SalePrice
X = as.matrix(X)
Y = as.matrix(Y)
dtrain = xgb.DMatrix(X,label=Y)
bst = xgb.train(params = param, data = dtrain, nrounds = nround, nthread = 2)
importance_matrix = xgb.importance(model = bst)
best_features = importance_matrix$Feature[1:25]
train_data = train_data[,c(best_features,"log1p_SalePrice")]
# 3 Tunning parameters for SVM
final_result = data.frame()
for (eps_value in seq(0,1,0.2)){
for (kernel_value in c("linear")){
err_vec_high = c()
for (rd_state in 1:20){
indexs = divide_data(train_data,rd_state)
err_vec = c()
for (i in 1:5){
train_batch = train_data[-indexs[[i]],c(best_features,"log1p_SalePrice")]
test_batch = train_data[indexs[[i]],c(best_features,"log1p_SalePrice")]
X = subset(train_batch,select = -log1p_SalePrice)
Y = train_batch$log1p_SalePrice
X = as.matrix(X)
Y = as.matrix(Y)
svm_model = svm(X,Y,eps=eps_value,kernel=kernel_value)
test_X = subset(test_batch,select = -log1p_SalePrice)
test_Y = test_batch$log1p_SalePrice
test_X = as.matrix(test_X)
test_Y = as.matrix(test_Y)
svm_prediction = predict(svm_model,test_X)
batch_err = rmse(test_Y,svm_prediction)
err_vec = c(err_vec,batch_err)
}
mean_cv_err = mean(err_vec)
err_vec_high = c(err_vec_high,mean_cv_err)
}
tem_result = c(eps_value,kernel_value,mean(err_vec_high))
print(tem_result)
final_result = rbind(final_result,tem_result)
}
}
library(caret)
library(glmnet)
library(e1071)
library(xgboost)
library(ModelMetrics)
# 0 Functions
# divide data into 5 folds
divide_data = function(data,rand_num){
set.seed(rand_num)
indexs = createFolds(1:dim(data)[1], k = 5, list = TRUE, returnTrain = FALSE)
return(indexs)
# test_data = data[indexs[[i]],]
# train_data = data[-indexs[[i]],]
}
# 1 Load data
train_data = read.csv("data/train_data_R.csv", stringsAsFactors=TRUE)
test_data = read.csv("data/test_data_R.csv", stringsAsFactors=TRUE)
train_data = subset(train_data,select = -X)
train_data = subset(train_data,select = -Id)
test_id = test_data$Id
test_data = subset(test_data,select = -X)
test_data = subset(test_data,select = -Id)
test_data = subset(test_data,select = -log1p_SalePrice)
# 2 Fit on the whole data set to get best_features(top25)
nround = 100
param = list(max_depth=2,eta=0.3, silent=0)
X = subset(train_data,select = -log1p_SalePrice)
Y = train_data$log1p_SalePrice
X = as.matrix(X)
Y = as.matrix(Y)
dtrain = xgb.DMatrix(X,label=Y)
bst = xgb.train(params = param, data = dtrain, nrounds = nround, nthread = 2)
importance_matrix = xgb.importance(model = bst)
best_features = importance_matrix$Feature[1:25]
train_data = train_data[,c(best_features,"log1p_SalePrice")]
# 3 Tunning parameters for SVM
final_result = data.frame()
for (eps_value in seq(0,1,0.1)){
for (kernel_value in c("linear")){
err_vec_high = c()
for (rd_state in 1:20){
indexs = divide_data(train_data,rd_state)
err_vec = c()
for (i in 1:5){
train_batch = train_data[-indexs[[i]],c(best_features,"log1p_SalePrice")]
test_batch = train_data[indexs[[i]],c(best_features,"log1p_SalePrice")]
X = subset(train_batch,select = -log1p_SalePrice)
Y = train_batch$log1p_SalePrice
X = as.matrix(X)
Y = as.matrix(Y)
svm_model = svm(X,Y,eps=eps_value,kernel=kernel_value)
test_X = subset(test_batch,select = -log1p_SalePrice)
test_Y = test_batch$log1p_SalePrice
test_X = as.matrix(test_X)
test_Y = as.matrix(test_Y)
svm_prediction = predict(svm_model,test_X)
batch_err = rmse(test_Y,svm_prediction)
err_vec = c(err_vec,batch_err)
}
mean_cv_err = mean(err_vec)
err_vec_high = c(err_vec_high,mean_cv_err)
}
tem_result = c(eps_value,kernel_value,mean(err_vec_high))
print(tem_result)
final_result = rbind(final_result,tem_result)
}
}
colnames(final_result)=c("gamma_value","kernel_type","cross-validation error")
View(final_result)
colnames(final_result)=c("eps_value","kernel_type","cross-validation error")
write.csv(final_result,file = "data/output/section2_svr_final_result.csv")
library(caret)
library(glmnet)
library(e1071)
library(xgboost)
library(ModelMetrics)
# 1 Load data
train_data = read.csv("data/train_data_R.csv", stringsAsFactors=TRUE)
test_data = read.csv("data/test_data_R.csv", stringsAsFactors=TRUE)
train_data = subset(train_data,select = -X)
train_data = subset(train_data,select = -Id)
test_id = test_data$Id
test_data = subset(test_data,select = -X)
test_data = subset(test_data,select = -Id)
test_data = subset(test_data,select = -log1p_SalePrice)
# 2 Fit on the whole data set to get best_features(top25)
nround = 100
param = list(max_depth=2,eta=0.3, silent=0)
X = subset(train_data,select = -log1p_SalePrice)
Y = train_data$log1p_SalePrice
X = as.matrix(X)
Y = as.matrix(Y)
dtrain = xgb.DMatrix(X,label=Y)
bst = xgb.train(params = param, data = dtrain, nrounds = nround, nthread = 2)
importance_matrix = xgb.importance(model = bst)
best_features = importance_matrix$Feature[1:25]
train_data = train_data[,c(best_features,"log1p_SalePrice")]
library(caret)
library(glmnet)
library(e1071)
library(xgboost)
library(ModelMetrics)
# 1 Load data
train_data = read.csv("data/train_data_R.csv", stringsAsFactors=TRUE)
test_data = read.csv("data/test_data_R.csv", stringsAsFactors=TRUE)
train_data = subset(train_data,select = -X)
train_data = subset(train_data,select = -Id)
test_id = test_data$Id
test_data = subset(test_data,select = -X)
test_data = subset(test_data,select = -Id)
test_data = subset(test_data,select = -log1p_SalePrice)
# 2 Fit on the whole data set to get best_features(top25)
nround = 100
param = list(max_depth=2,eta=0.3, silent=0)
X = subset(train_data,select = -log1p_SalePrice)
Y = train_data$log1p_SalePrice
X = as.matrix(X)
Y = as.matrix(Y)
dtrain = xgb.DMatrix(X,label=Y)
bst = xgb.train(params = param, data = dtrain, nrounds = nround, nthread = 2)
importance_matrix = xgb.importance(model = bst)
best_features = importance_matrix$Feature[1:25]
train_data = train_data[,c(best_features,"log1p_SalePrice")]
X = subset(train_data,select = -log1p_SalePrice)
Y = train_data$log1p_SalePrice
X = as.matrix(X)
Y = as.matrix(Y)
X
Y
eps_value = 0.1
kernel_value = "linear"
X = subset(train_data,select = -log1p_SalePrice)
Y = train_data$log1p_SalePrice
X = as.matrix(X)
Y = as.matrix(Y)
svm_model = svm(X,Y,eps=eps_value,kernel=kernel_value)
print("Fitting rmse is:")
print(rmse(predict(svm_model,X),Y))
test_data = test_data[,best_features]
submission_prediction = predict(svm_model,as.matrix(test_data))
submission_prediction
SalePrice = exp(submission_prediction)-1
SalePrice
section2_svr_submission = cbind(test_id,SalePrice)
section2_svr_submission = as.data.frame(section2_svr_submission)
section2_svr_submission
colnames(section2_svr_submission) = c("Id","SalePrice")
View(section2_svr_submission)
library(caret)
library(glmnet)
library(e1071)
library(xgboost)
library(ModelMetrics)
# 1 Load data
train_data = read.csv("data/train_data_R.csv", stringsAsFactors=TRUE)
test_data = read.csv("data/test_data_R.csv", stringsAsFactors=TRUE)
train_data = subset(train_data,select = -X)
train_data = subset(train_data,select = -Id)
test_id = test_data$Id
test_data = subset(test_data,select = -X)
test_data = subset(test_data,select = -Id)
test_data = subset(test_data,select = -log1p_SalePrice)
# 2 Fit on the whole data set to get best_features(top25)
nround = 100
param = list(max_depth=2,eta=0.3, silent=0)
X = subset(train_data,select = -log1p_SalePrice)
Y = train_data$log1p_SalePrice
X = as.matrix(X)
Y = as.matrix(Y)
dtrain = xgb.DMatrix(X,label=Y)
bst = xgb.train(params = param, data = dtrain, nrounds = nround, nthread = 2)
importance_matrix = xgb.importance(model = bst)
best_features = importance_matrix$Feature[1:25]
train_data = train_data[,c(best_features,"log1p_SalePrice")]
test_data = test_data[,best_features]
# 3 Fitting SVM
eps_value = 0.1
kernel_value = "linear"
X = subset(train_data,select = -log1p_SalePrice)
Y = train_data$log1p_SalePrice
X = as.matrix(X)
Y = as.matrix(Y)
svm_model = svm(X,Y,eps=eps_value,kernel=kernel_value)
print("Fitting rmse is:")
print(rmse(predict(svm_model,X),Y))
# 4 Make prediction
submission_prediction = predict(svm_model,as.matrix(test_data))
SalePrice = exp(submission_prediction)-1
section2_svr_submission = cbind(test_id,SalePrice)
section2_svr_submission = as.data.frame(section2_svr_submission)
colnames(section2_svr_submission) = c("Id","SalePrice")
write.csv(section2_svr_submission,file = "data/output/section2_svr_submission.csv",row.names = FALSE)
# 1 Load data
lasso_submission= read.csv("data/output/section2_lasso_submission.csv", stringsAsFactors=TRUE)
View(lasso_submission)
View(lasso_submission)
# 1 Load data
lasso_submission= read.csv("data/output/section2_lasso_submission.csv", stringsAsFactors=TRUE)
svr_submission= read.csv("data/output/section2_svr_submission.csv", stringsAsFactors=TRUE)
xgb_submission= read.csv("data/output/section2_xgb_submission.csv", stringsAsFactors=TRUE)
View(lasso_submission)
View(svr_submission)
str(12)
str(12)
as.character(123)
paste0(as.character(123),as.character(123),as.character(123),as.character(123))
# 1 Load data
lasso_submission= read.csv("data/output/section2_lasso_submission.csv", stringsAsFactors=TRUE)
svr_submission= read.csv("data/output/section2_svr_submission.csv", stringsAsFactors=TRUE)
xgb_submission= read.csv("data/output/section2_xgb_submission.csv", stringsAsFactors=TRUE)
# 2 lasso+xgb
for (weight in c(0.2,0.4,0.6.0.8)){
print(weight)
}
for (weight in c(0.2,0.4,0.6.0.8)){
print(weight)
}
for (model_weight in c(0.2,0.4,0.6.0.8)){
print(model_weight)
}
# 2 lasso+xgb
for (model_weight in c(0.2,0.4,0.6,0.8)){
print(model_weight)
}
stacking = svr_submission
# 2 lasso+xgb
stacking = svr_submission
stacking$SalePrice = 0
stacking\
stacking
# 2 lasso+xgb
stacking = svr_submission
stacking$SalePrice = 0
for (model_weight in c(0.2,0.4,0.6,0.8)){
print(model_weight)
stacking$SalePrice = model_weight*lasso_submission$SalePrice+(1-model_weight)*xgb_submission$SalePrice
}
stacking
as.character(model_weight)
paste0(as.character(model_weight),"_")
paste0(as.character(model_weight),"_lasso_xgb")
paste0("data/output/section3_",as.character(model_weight),"_lasso_xgb.csv")
# 1 Load data
lasso_submission= read.csv("data/output/section2_lasso_submission.csv", stringsAsFactors=TRUE)
svr_submission= read.csv("data/output/section2_svr_submission.csv", stringsAsFactors=TRUE)
xgb_submission= read.csv("data/output/section2_xgb_submission.csv", stringsAsFactors=TRUE)
# 2 lasso+xgb
stacking = svr_submission
stacking$SalePrice = 0
for (model_weight in c(0.2,0.4,0.6,0.8)){
stacking$SalePrice = model_weight*lasso_submission$SalePrice+(1-model_weight)*xgb_submission$SalePrice
save_str = paste0("data/output/section3_",as.character(model_weight),"_lasso_xgb.csv")
write.csv(section2_lasso_submission,file = save_str,row.names = FALSE)
}
# 1 Load data
lasso_submission= read.csv("data/output/section2_lasso_submission.csv", stringsAsFactors=TRUE)
svr_submission= read.csv("data/output/section2_svr_submission.csv", stringsAsFactors=TRUE)
xgb_submission= read.csv("data/output/section2_xgb_submission.csv", stringsAsFactors=TRUE)
save_str = paste0("data/output/section3_",as.character(model_weight),"_lasso_xgb.csv")
save_str
write.csv(section2_lasso_submission,file = save_str,row.names = FALSE)
# 1 Load data
lasso_submission= read.csv("data/output/section2_lasso_submission.csv", stringsAsFactors=TRUE)
svr_submission= read.csv("data/output/section2_svr_submission.csv", stringsAsFactors=TRUE)
xgb_submission= read.csv("data/output/section2_xgb_submission.csv", stringsAsFactors=TRUE)
# 2 lasso+xgb
stacking = svr_submission
stacking$SalePrice = 0
for (model_weight in c(0.2,0.4,0.6,0.8)){
stacking$SalePrice = model_weight*lasso_submission$SalePrice+(1-model_weight)*xgb_submission$SalePrice
save_str = paste0("data/output/section3_",as.character(model_weight),"_lasso_xgb.csv")
write.csv(stacking,file = save_str,row.names = FALSE)
}
3620/9888
3620/9902
stacking = svr_submission
stacking$SalePrice = 0
# 3 svr+xgb
stacking = svr_submission
stacking$SalePrice = 0
for (model_weight in c(0.2,0.4,0.6,0.8)){
stacking$SalePrice = model_weight*svr_submission$SalePrice+(1-model_weight)*xgb_submission$SalePrice
save_str = paste0("data/output/section3_",as.character(model_weight),"_svr_xgb.csv")
write.csv(stacking,file = save_str,row.names = FALSE)
}
9902
9902
3621/9907
36.54%
36.54%
3623/9923
library(bazar)
library(tidyverse)
library(Hmisc)
library(dummies)
# 1 Load data
train_data = read.csv("data/original_data/train.csv", stringsAsFactors=TRUE)
View(train_data)
test_data = read.csv("data/original_data/test.csv", stringsAsFactors=TRUE)
(84+95)/2
